{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offensive Language Identification\n",
    "\n",
    "This is the task 'a' in Task 6: OffensEval: Identifying and Categorizing Offensive Language in Social Media in SemEval 2019. We have explored how  CNN (2D Convolution) can be used in Offensive language identification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from keras.callbacks import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get reproducable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "seed(726)\n",
    "set_random_seed(726)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and testing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (13240, 5)\n",
      "Test shape :  (860, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"Data/training/offenseval-training-v1.tsv\", sep='\\t')\n",
    "\n",
    "test_tweets = pd.read_csv(\"Data/testing/testset-taska.tsv\", sep='\\t')\n",
    "test_labels = pd.read_csv(\"Data/testing/labels-test-a.csv\", header=-1, names = [\"id\", \"subtask_a\"])\n",
    "\n",
    "test = pd.merge(test_tweets, test_labels, on=['id','id'])\n",
    "print(\"Train shape : \", train.shape)\n",
    "print(\"Test shape : \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing case of the tweets to lower case, since the embedding model only has lower case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tweet\"] = train[\"tweet\"].str.lower()\n",
    "test[\"tweet\"] = test[\"tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the puncutation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda x: clean_text(x))\n",
    "test[\"tweet\"] = test[\"tweet\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OFF', 'OFF', 'NOT', ..., 'OFF', 'OFF', 'NOT'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = None # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 72 # max number of words in a question to use #99.99%\n",
    "\n",
    "## fill up the missing values\n",
    "X = train[\"tweet\"].fillna(\"_na_\").values\n",
    "X_test = test[\"tweet\"].fillna(\"_na_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "tokenizer.fit_on_texts(list(X))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "## Pad the sentences \n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "Y = train['subtask_a'].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(Y)\n",
    "encoded_Y = le.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "max_features = len(word_index)+1\n",
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '/data/glove/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if o.split(\" \")[0] in word_index)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix \n",
    "    \n",
    "def load_fasttext(word_index):    \n",
    "    EMBEDDING_FILE = '/data/fasttext/crawl-300d-2M-subword.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100 and o.split(\" \")[0] in word_index )\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Glove vectors have been used in embedding matrix. Can explore it further in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = load_glove(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sizes = [1,2,3,5]\n",
    "num_filters = 32\n",
    "\n",
    "def get_model():    \n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Reshape((maxlen, embed_size, 1))(x)\n",
    "    \n",
    "    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    \n",
    "    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n",
    "    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n",
    "    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n",
    "    maxpool_3 = MaxPool2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n",
    "        \n",
    "    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "        \n",
    "    outp = Dense(1, activation=\"sigmoid\")(z)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_smart(y_true, y_pred):\n",
    "    args = np.argsort(y_pred)\n",
    "    tp = y_true.sum()\n",
    "    fs = (tp - np.cumsum(y_true[args[:-1]])) / np.arange(y_true.shape[0] + tp - 1, tp, -1)\n",
    "    res_idx = np.argmax(fs)\n",
    "    return 2 * fs[res_idx], (y_pred[args[res_idx]] + y_pred[args[res_idx + 1]]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with early stopping and reducing learning rate on plateu. In each fold values for the test set is also predicted, And after the process, predicted values for the test file would be mean from each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 72)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 72, 300)      6036600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 72, 300)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 72, 300, 1)   0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 1, 32)    9632        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 71, 1, 32)    19232       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 70, 1, 32)    28832       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 68, 1, 32)    48032       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 32)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 32)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 32)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 32)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 1, 32)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,142,457\n",
      "Trainable params: 6,142,457\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10592 samples, validate on 2648 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.5958 - acc: 0.7016 - val_loss: 0.4581 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45811, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 12s - loss: 0.4558 - acc: 0.7909 - val_loss: 0.4465 - val_acc: 0.7968\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45811 to 0.44650, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 12s - loss: 0.4077 - acc: 0.8131 - val_loss: 0.4568 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.44650\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.3589 - acc: 0.8450 - val_loss: 0.4523 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44650\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 5/20\n",
      " - 12s - loss: 0.3229 - acc: 0.8616 - val_loss: 0.4565 - val_acc: 0.7949\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44650\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 6/20\n",
      " - 12s - loss: 0.3016 - acc: 0.8718 - val_loss: 0.4603 - val_acc: 0.7961\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44650\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 7/20\n",
      " - 12s - loss: 0.2900 - acc: 0.8815 - val_loss: 0.4623 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44650\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 8/20\n",
      " - 12s - loss: 0.2773 - acc: 0.8840 - val_loss: 0.4648 - val_acc: 0.7953\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44650\n",
      "Epoch 9/20\n",
      " - 12s - loss: 0.2711 - acc: 0.8888 - val_loss: 0.4677 - val_acc: 0.7931\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44650\n",
      "Epoch 10/20\n",
      " - 12s - loss: 0.2686 - acc: 0.8898 - val_loss: 0.4708 - val_acc: 0.7919\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44650\n",
      "Epoch 11/20\n",
      " - 12s - loss: 0.2591 - acc: 0.8958 - val_loss: 0.4770 - val_acc: 0.7855\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44650\n",
      "Epoch 12/20\n",
      " - 12s - loss: 0.2585 - acc: 0.8943 - val_loss: 0.4748 - val_acc: 0.7912\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.44650\n",
      "Epoch 13/20\n",
      " - 12s - loss: 0.2454 - acc: 0.9020 - val_loss: 0.4775 - val_acc: 0.7885\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.44650\n",
      "Epoch 14/20\n",
      " - 12s - loss: 0.2439 - acc: 0.9054 - val_loss: 0.4847 - val_acc: 0.7847\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.44650\n",
      "Epoch 15/20\n",
      " - 12s - loss: 0.2362 - acc: 0.9080 - val_loss: 0.4874 - val_acc: 0.7836\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.44650\n",
      "Epoch 16/20\n",
      " - 12s - loss: 0.2287 - acc: 0.9102 - val_loss: 0.4877 - val_acc: 0.7836\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.44650\n",
      "Epoch 17/20\n",
      " - 12s - loss: 0.2234 - acc: 0.9133 - val_loss: 0.4892 - val_acc: 0.7889\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.44650\n",
      "Epoch 18/20\n",
      " - 12s - loss: 0.2184 - acc: 0.9172 - val_loss: 0.4953 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.44650\n",
      "Epoch 19/20\n",
      " - 12s - loss: 0.2173 - acc: 0.9145 - val_loss: 0.4982 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.44650\n",
      "Epoch 20/20\n",
      " - 12s - loss: 0.2096 - acc: 0.9222 - val_loss: 0.5002 - val_acc: 0.7821\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.44650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal F1: 0.6928 at threshold: 0.3519\n",
      "Train on 10592 samples, validate on 2648 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.5736 - acc: 0.7133 - val_loss: 0.4790 - val_acc: 0.7757\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47905, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 12s - loss: 0.4538 - acc: 0.7914 - val_loss: 0.4722 - val_acc: 0.7847\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.47905 to 0.47218, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 12s - loss: 0.4057 - acc: 0.8162 - val_loss: 0.4724 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.47218\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.3499 - acc: 0.8466 - val_loss: 0.4789 - val_acc: 0.7806\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47218\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 5/20\n",
      " - 12s - loss: 0.3104 - acc: 0.8701 - val_loss: 0.4924 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47218\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 6/20\n",
      " - 13s - loss: 0.2990 - acc: 0.8735 - val_loss: 0.4920 - val_acc: 0.7806\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47218\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 7/20\n",
      " - 12s - loss: 0.2835 - acc: 0.8798 - val_loss: 0.4890 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47218\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 8/20\n",
      " - 12s - loss: 0.2721 - acc: 0.8886 - val_loss: 0.4909 - val_acc: 0.7787\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.47218\n",
      "Epoch 9/20\n",
      " - 12s - loss: 0.2709 - acc: 0.8876 - val_loss: 0.4915 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.47218\n",
      "Epoch 10/20\n",
      " - 12s - loss: 0.2627 - acc: 0.8913 - val_loss: 0.4994 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.47218\n",
      "Epoch 11/20\n",
      " - 12s - loss: 0.2532 - acc: 0.8973 - val_loss: 0.5033 - val_acc: 0.7791\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.47218\n",
      "Epoch 12/20\n",
      " - 12s - loss: 0.2543 - acc: 0.8950 - val_loss: 0.5006 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.47218\n",
      "Epoch 13/20\n",
      " - 12s - loss: 0.2442 - acc: 0.9036 - val_loss: 0.5069 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.47218\n",
      "Epoch 14/20\n",
      " - 12s - loss: 0.2401 - acc: 0.9033 - val_loss: 0.5072 - val_acc: 0.7791\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.47218\n",
      "Epoch 15/20\n",
      " - 12s - loss: 0.2328 - acc: 0.9076 - val_loss: 0.5125 - val_acc: 0.7779\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.47218\n",
      "Epoch 16/20\n",
      " - 13s - loss: 0.2267 - acc: 0.9100 - val_loss: 0.5205 - val_acc: 0.7776\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.47218\n",
      "Epoch 17/20\n",
      " - 12s - loss: 0.2242 - acc: 0.9113 - val_loss: 0.5182 - val_acc: 0.7764\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.47218\n",
      "Epoch 18/20\n",
      " - 12s - loss: 0.2190 - acc: 0.9126 - val_loss: 0.5217 - val_acc: 0.7757\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.47218\n",
      "Epoch 19/20\n",
      " - 13s - loss: 0.2081 - acc: 0.9206 - val_loss: 0.5247 - val_acc: 0.7768\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.47218\n",
      "Epoch 20/20\n",
      " - 13s - loss: 0.2042 - acc: 0.9223 - val_loss: 0.5287 - val_acc: 0.7764\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.47218\n",
      "Optimal F1: 0.6860 at threshold: 0.3866\n",
      "Train on 10592 samples, validate on 2648 samples\n",
      "Epoch 1/20\n",
      " - 14s - loss: 0.5714 - acc: 0.7143 - val_loss: 0.4685 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46853, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 13s - loss: 0.4584 - acc: 0.7937 - val_loss: 0.4649 - val_acc: 0.7874\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46853 to 0.46495, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 12s - loss: 0.4055 - acc: 0.8177 - val_loss: 0.4527 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46495 to 0.45266, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.3539 - acc: 0.8440 - val_loss: 0.4679 - val_acc: 0.7893\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45266\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 5/20\n",
      " - 12s - loss: 0.3103 - acc: 0.8694 - val_loss: 0.4681 - val_acc: 0.7878\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45266\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 6/20\n",
      " - 12s - loss: 0.2752 - acc: 0.8852 - val_loss: 0.4734 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45266\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 7/20\n",
      " - 12s - loss: 0.2584 - acc: 0.8948 - val_loss: 0.4954 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45266\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 8/20\n",
      " - 12s - loss: 0.2436 - acc: 0.9051 - val_loss: 0.4912 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45266\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 9/20\n",
      " - 12s - loss: 0.2338 - acc: 0.9078 - val_loss: 0.4980 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45266\n",
      "Epoch 10/20\n",
      " - 12s - loss: 0.2304 - acc: 0.9109 - val_loss: 0.5065 - val_acc: 0.7776\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45266\n",
      "Epoch 11/20\n",
      " - 12s - loss: 0.2238 - acc: 0.9139 - val_loss: 0.5071 - val_acc: 0.7791\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45266\n",
      "Epoch 12/20\n",
      " - 12s - loss: 0.2103 - acc: 0.9182 - val_loss: 0.5101 - val_acc: 0.7779\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45266\n",
      "Epoch 13/20\n",
      " - 12s - loss: 0.2128 - acc: 0.9172 - val_loss: 0.5056 - val_acc: 0.7840\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45266\n",
      "Epoch 14/20\n",
      " - 12s - loss: 0.2070 - acc: 0.9226 - val_loss: 0.5132 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45266\n",
      "Epoch 15/20\n",
      " - 12s - loss: 0.1998 - acc: 0.9229 - val_loss: 0.5168 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45266\n",
      "Epoch 16/20\n",
      " - 12s - loss: 0.1955 - acc: 0.9267 - val_loss: 0.5241 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45266\n",
      "Epoch 17/20\n",
      " - 12s - loss: 0.1919 - acc: 0.9264 - val_loss: 0.5275 - val_acc: 0.7787\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45266\n",
      "Epoch 18/20\n",
      " - 12s - loss: 0.1866 - acc: 0.9325 - val_loss: 0.5322 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45266\n",
      "Epoch 19/20\n",
      " - 12s - loss: 0.1792 - acc: 0.9345 - val_loss: 0.5310 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.45266\n",
      "Epoch 20/20\n",
      " - 12s - loss: 0.1754 - acc: 0.9358 - val_loss: 0.5375 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.45266\n",
      "Optimal F1: 0.6924 at threshold: 0.3734\n",
      "Train on 10592 samples, validate on 2648 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.5654 - acc: 0.7107 - val_loss: 0.4598 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45983, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 12s - loss: 0.4545 - acc: 0.7850 - val_loss: 0.4517 - val_acc: 0.7919\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45983 to 0.45171, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 12s - loss: 0.4042 - acc: 0.8161 - val_loss: 0.4694 - val_acc: 0.7836\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45171\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.3530 - acc: 0.8404 - val_loss: 0.4440 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45171 to 0.44396, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 5/20\n",
      " - 12s - loss: 0.3185 - acc: 0.8611 - val_loss: 0.4731 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44396\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 6/20\n",
      " - 12s - loss: 0.2863 - acc: 0.8806 - val_loss: 0.4688 - val_acc: 0.7866\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44396\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 7/20\n",
      " - 12s - loss: 0.2655 - acc: 0.8890 - val_loss: 0.4748 - val_acc: 0.7836\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44396\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 8/20\n",
      " - 12s - loss: 0.2549 - acc: 0.8940 - val_loss: 0.4760 - val_acc: 0.7836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44396\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 9/20\n",
      " - 12s - loss: 0.2468 - acc: 0.8981 - val_loss: 0.4782 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44396\n",
      "Epoch 10/20\n",
      " - 12s - loss: 0.2409 - acc: 0.9040 - val_loss: 0.4845 - val_acc: 0.7813\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44396\n",
      "Epoch 11/20\n",
      " - 12s - loss: 0.2379 - acc: 0.9053 - val_loss: 0.4852 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44396\n",
      "Epoch 12/20\n",
      " - 12s - loss: 0.2276 - acc: 0.9103 - val_loss: 0.4879 - val_acc: 0.7779\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.44396\n",
      "Epoch 13/20\n",
      " - 12s - loss: 0.2219 - acc: 0.9108 - val_loss: 0.4940 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.44396\n",
      "Epoch 14/20\n",
      " - 12s - loss: 0.2186 - acc: 0.9149 - val_loss: 0.4966 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.44396\n",
      "Epoch 15/20\n",
      " - 12s - loss: 0.2126 - acc: 0.9163 - val_loss: 0.4933 - val_acc: 0.7772\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.44396\n",
      "Epoch 16/20\n",
      " - 12s - loss: 0.2025 - acc: 0.9222 - val_loss: 0.4987 - val_acc: 0.7779\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.44396\n",
      "Epoch 17/20\n",
      " - 12s - loss: 0.2003 - acc: 0.9234 - val_loss: 0.5067 - val_acc: 0.7745\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.44396\n",
      "Epoch 18/20\n",
      " - 13s - loss: 0.1948 - acc: 0.9252 - val_loss: 0.5121 - val_acc: 0.7761\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.44396\n",
      "Epoch 19/20\n",
      " - 13s - loss: 0.1916 - acc: 0.9270 - val_loss: 0.5126 - val_acc: 0.7727\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.44396\n",
      "Epoch 20/20\n",
      " - 13s - loss: 0.1813 - acc: 0.9294 - val_loss: 0.5140 - val_acc: 0.7727\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.44396\n",
      "Optimal F1: 0.6990 at threshold: 0.4532\n",
      "Train on 10592 samples, validate on 2648 samples\n",
      "Epoch 1/20\n",
      " - 15s - loss: 0.5630 - acc: 0.7193 - val_loss: 0.4656 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46560, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 16s - loss: 0.4583 - acc: 0.7893 - val_loss: 0.4565 - val_acc: 0.7912\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46560 to 0.45654, saving model to Models/cnn_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 15s - loss: 0.4045 - acc: 0.8174 - val_loss: 0.4711 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45654\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 4/20\n",
      " - 16s - loss: 0.3567 - acc: 0.8441 - val_loss: 0.4618 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45654\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 5/20\n",
      " - 16s - loss: 0.3204 - acc: 0.8606 - val_loss: 0.4581 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45654\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 6/20\n",
      " - 16s - loss: 0.2988 - acc: 0.8711 - val_loss: 0.4651 - val_acc: 0.7972\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45654\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 7/20\n",
      " - 16s - loss: 0.2865 - acc: 0.8795 - val_loss: 0.4652 - val_acc: 0.7953\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45654\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 8/20\n",
      " - 16s - loss: 0.2798 - acc: 0.8851 - val_loss: 0.4696 - val_acc: 0.7923\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45654\n",
      "Epoch 9/20\n",
      " - 15s - loss: 0.2703 - acc: 0.8909 - val_loss: 0.4693 - val_acc: 0.7938\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45654\n",
      "Epoch 10/20\n",
      " - 15s - loss: 0.2653 - acc: 0.8894 - val_loss: 0.4728 - val_acc: 0.7938\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45654\n",
      "Epoch 11/20\n",
      " - 15s - loss: 0.2594 - acc: 0.8925 - val_loss: 0.4737 - val_acc: 0.7938\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45654\n",
      "Epoch 12/20\n",
      " - 15s - loss: 0.2500 - acc: 0.8995 - val_loss: 0.4762 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45654\n",
      "Epoch 13/20\n",
      " - 15s - loss: 0.2473 - acc: 0.9013 - val_loss: 0.4778 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45654\n",
      "Epoch 14/20\n",
      " - 15s - loss: 0.2417 - acc: 0.9010 - val_loss: 0.4899 - val_acc: 0.7893\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45654\n",
      "Epoch 15/20\n",
      " - 15s - loss: 0.2363 - acc: 0.9071 - val_loss: 0.4898 - val_acc: 0.7881\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45654\n",
      "Epoch 16/20\n",
      " - 15s - loss: 0.2308 - acc: 0.9098 - val_loss: 0.4880 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45654\n",
      "Epoch 17/20\n",
      " - 15s - loss: 0.2263 - acc: 0.9111 - val_loss: 0.4905 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45654\n",
      "Epoch 18/20\n",
      " - 15s - loss: 0.2248 - acc: 0.9107 - val_loss: 0.4932 - val_acc: 0.7923\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45654\n",
      "Epoch 19/20\n",
      " - 15s - loss: 0.2169 - acc: 0.9166 - val_loss: 0.4982 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.45654\n",
      "Epoch 20/20\n",
      " - 15s - loss: 0.2095 - acc: 0.9225 - val_loss: 0.5004 - val_acc: 0.7915\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.45654\n",
      "Optimal F1: 0.6918 at threshold: 0.3946\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=10, shuffle=True)\n",
    "bestscore = []\n",
    "y_test = np.zeros((X_test.shape[0], ))\n",
    "for i, (train_index, valid_index) in enumerate(kfold.split(X, encoded_Y)):\n",
    "    X_train, X_val, Y_train, Y_val = X[train_index], X[valid_index], encoded_Y[train_index], encoded_Y[valid_index]\n",
    "    filepath=\"Models/cnn_weights_best.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=1, min_lr=0.0001, verbose=2)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=2, mode='auto')\n",
    "    callbacks = [checkpoint, reduce_lr]\n",
    "    model = get_model()\n",
    "    if i == 0:print(model.summary()) \n",
    "    model.fit(X_train, Y_train, batch_size=64, epochs=20, validation_data=(X_val, Y_val), verbose=2, callbacks=callbacks, \n",
    "             )\n",
    "    model.load_weights(filepath)\n",
    "    y_pred = model.predict([X_val], batch_size=64, verbose=2)\n",
    "    y_test += np.squeeze(model.predict([X_test], batch_size=64, verbose=2))/5\n",
    "    f1, threshold = f1_smart(np.squeeze(Y_val), np.squeeze(y_pred))\n",
    "    print('Optimal F1: {:.4f} at threshold: {:.4f}'.format(f1, threshold))\n",
    "    bestscore.append(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the predictions for integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py:273: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test.reshape((-1, 1))\n",
    "pred_test_y = (y_test>np.mean(bestscore)).astype(int)\n",
    "test['predictions'] = le.inverse_transform(pred_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 71, 68, 172)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(test[\"subtask_a\"], test['predictions']).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from visualization.confusion_matrix_pretty_print import plot_confusion_matrix_from_data\n",
    "\n",
    "columns = []\n",
    "annot = True\n",
    "cmap = 'Oranges'\n",
    "fmt = '.2f'\n",
    "lw = 0.5\n",
    "cbar = False\n",
    "show_null_values = 2\n",
    "pred_val_axis = 'y'\n",
    "# size::\n",
    "fz = 12;\n",
    "figsize = [9, 9];\n",
    "if len(y_test) > 10:\n",
    "    fz = 9;\n",
    "    figsize = [14, 14];\n",
    "plot_confusion_matrix_from_data(test[\"subtask_a\"], test['predictions'], columns,\n",
    "                                    annot, cmap, fmt, fz, lw, cbar, figsize, show_null_values, pred_val_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8383720930232558"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test[\"subtask_a\"], test['predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sentence_similarity_3.6]",
   "language": "python",
   "name": "conda-env-sentence_similarity_3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
